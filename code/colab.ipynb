{"cells":[{"cell_type":"markdown","metadata":{"id":"dpeLV_OwAODE"},"source":["**Mount drive to file system**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XhKu8JotAISU"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"A8o2HzuzIV2g"},"source":["**Unzip images and segmentation data to local drive**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M7wINZdTAY43"},"outputs":[],"source":["%cd /content/drive/MyDrive/Machine Learning/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MvRsZlaMyL4E"},"outputs":[],"source":["!mkdir ~/images\n","!mkdir ~/segm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5djTvYUgyWZ0"},"outputs":[],"source":["!unzip images.zip -d ~/images/\n","!unzip segm.zip -d ~/segm/"]},{"cell_type":"markdown","metadata":{"id":"Nfr5eW2eAWST"},"source":["**Install missing dependencies for diffusers**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UvV95SYFAfc6"},"outputs":[],"source":["!pip install diffusers\n","!pip install accelerate\n","!pip install lpips\n","!pip install deepspeed\n","!pip install bitsandbytes"]},{"cell_type":"markdown","metadata":{"id":"0vof_QPKrvoS"},"source":["**Go to the root project directory**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GLCL5x49B6g-"},"outputs":[],"source":["%cd \"/content/drive/MyDrive/Machine Learning/unet_boundary_xl\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8b36avDagmu"},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VEDaoz1UaP7w"},"outputs":[],"source":["!rm -rf ./default/logs/\n","%tensorboard --logdir \"./default/logs/seg512\""]},{"cell_type":"markdown","metadata":{"id":"cEPODIJTrvoS"},"source":["**Pretrain with simple bottleneck**\n","\n","--resume_from_checkpoint=latest     resumes from the most recent checkpoint\n","\n","--checkpoint_to_output              unwraps the model from accelerate and saves it to out_file_name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzo3_VKtC1-D"},"outputs":[],"source":["!python run.py --output_file_name=\"output.default.512.params\" --checkpoints_total_limit=1  --raw_data_dir=\"/root/images/images/\" --label_data_dir=\"/root/segm/segm/\" --epochs_before_validate=1 --fit_width --train_batch_size=2 --num_train_epochs=3 --learning_rate=1e-3 --output_dir=./default/ --mixed_precision=no --checkpointing_steps=90 --gradient_accumulation_steps=32 --model_bottleneck=default --model_norm=GroupNorm\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtG6clo40SUc"},"outputs":[],"source":["!rm -rf ./default_attention/logs/\n","%tensorboard --logdir \"./default_attention/logs/seg512\""]},{"cell_type":"markdown","metadata":{"id":"RSiwoOxtrvoS"},"source":["**Upgrade Bottleneck**\n","\n","train just the bottleneck for an epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ra4_jKiByPLY"},"outputs":[],"source":["!python run.py --pretrained_model_path=\"./default/output.default.512.params\" --output_file_name=\"output.default_attention.512.params\" --checkpoints_total_limit=1  --raw_data_dir=\"/root/images/images/\" --label_data_dir=\"/root/segm/segm/\" --epochs_before_validate=1 --fit_width --train_batch_size=1 --num_train_epochs=1 --learning_rate=1e-4 --output_dir=./default_attention/ --mixed_precision=no --checkpointing_steps=90 --gradient_accumulation_steps=64 --model_bottleneck=default --model_norm=GroupNorm --upgrade_bottleneck=attention\n"]},{"cell_type":"markdown","metadata":{"id":"D6QWTcAGrvoS"},"source":["**Train Entire Model**\n","\n","You can probably get away with using a higher training rate here!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C_TS6bZG7x9t"},"outputs":[],"source":["!rm -rf ./attention/logs/\n","%tensorboard --logdir \"./attention/logs/seg512\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_1MQ9nWD7yPZ"},"outputs":[],"source":["!python run.py --pretrained_model_path=\"./attention/output.attention.512.params\" --output_file_name=\"output.ft.params\" --checkpoints_total_limit=1  --raw_data_dir=\"/root/images/images/\" --label_data_dir=\"/root/segm/segm/\" --epochs_before_validate=1 --fit_width --train_batch_size=1 --num_train_epochs=12 --learning_rate=1e-4 --output_dir=./attention/ --mixed_precision=no --checkpointing_steps=90 --gradient_accumulation_steps=64 --model_bottleneck=attention --model_norm=GroupNorm\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1rqFw9BRg_yhShilQiDVHBVOA9Jw-DoA5","timestamp":1709069560310}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}